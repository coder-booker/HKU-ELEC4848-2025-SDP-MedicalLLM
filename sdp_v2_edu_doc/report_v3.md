


# 为什么要改
- 原本的方向实在太过饱和了
- 我想到的创新点很难量化，也很难去分析






# 新方向
- LLM 赋能临床推理教学平台
    - 临床推理领域的教学
        - 有哪些临床步骤维度值得进行教学
            - General 临床推理
    - LLM 评估 + 维度限制评估
        - 有哪些评估方法
            - 数据集的金标对比，LLM 对比打分
            - self-consistency，LLM 生成答案
    - 学生个人化评估
        - 有哪些能力维度
            - 专一些的
                - 某些步骤的弱点？
                - 某些领域的弱点？
            - 整体
                - 广度/全面性？
                - 深度？
                - 真实性？
                - 生成个人化自然语言报告
    - 数据集
        - 分类
            - 能够支持不同过程打分的（比如只有结果没有讲解的）
            - 能够支持不同结果打分的（比如只有ABCD还是有解释）
            - 能够分为不同专科（比如分为心脏科、皮肤科之类的）
    - 结构化模块
        - 题目步骤模块，打分模块，评估模块
        - 可以设立要评估哪些步骤，最终的评估能力是什么

- 这三者似乎是缓缓相扣的：临床推理步骤决定了有哪些学生能力维度能够评估，也决定了 LLM 要评估哪些方向



优点：
1. 降低使用门槛（包含评估技术的实践，统合好的 benchmark 等等）
2. 成套、客制化的评估报告

似乎能做的特点：
1. 模拟学生来让倒是验证题目可行不可行



# report brainstorm
- Introduction
    - LLM 赋能的医学推理教育平台
- motivation
    - 此前，计算机的解难能力一直在被发掘和提升，但到了LLM的问世，其解难能力立刻跃升了一个层次
    - 【过得去就行，无人在意】LLM 是原本的计算机要解决‘语言与文字’这个相当复杂问题的最后一块拼图，其潜力巨大。当当今社会的很多问题都和‘文字’有关时，LLM 几乎是一个通解。
    - 而到了 medical reasoing 领域，LLM 就能解决很多问题了。除去各种计算机能够量化的化验、检查、数据分析，‘临床诊断’，‘病历撰写’，‘设计治疗方案’等等很难用传统计算机自动化的，需要用到医生的文字语言推理能力的任务，现在可以被 LLM 优化了。
    - 实不相瞒，我一开始的方向是 LLM 能够怎么辅助临床推理。然后我发现这个领域已经相当饱和了，从各种不同的 LLM 优化技巧到完善的benchmark数据集，几乎所有角度都有成熟的工作了。因此我决定脱离‘LLM 如何帮助医学推理’这个问题，转而从‘LLM 帮助医学推理有什么应用’角度出发。
    - 随后我便涉足了‘教育’领域。我希望能够基于现有对 ‘LLM 如何帮助 medical reasoning’ 的研究，结合 LLM 在教育领域的潜力，将其应用在‘教导医学生如何进行医学推理工作’。
- how
- why other can't fit


- report draft 的格式问题
    - 我需要给出那么详尽的‘motivation’吗？从传统计算机与LLM的能力差异推到自然语言在医学领域的用途再到LLM可以辅助。我其实是不是直接把我的产品说出来，然后翻过来推就行？不需要涉及那么底层的东西？比如我想做一个临床推理教学产品推到因为LLM很有能力解决医学自然语言问题而教育是一个很好的形式（我问这个问题的原因是我需要知晓‘why not other’的边界在哪：我知道‘为什么不是其他’这个问题十分重要，但如果对每一件事都做这个分析，可以问出无穷无尽的‘why not other’。）
    - 回答：
        - 很多高校给的研究 proposal / thesis proposal 建议是：motivation/intro 要做到这几点就够了：
            - 说明 问题领域 在现实和学术上的重要性
            - 指出 目前已有工作 做到了什么
            - 清晰说出 还缺什么（gap）
            - 自己的工作 填补这个 gap 的方式
        - 不需要详尽讨论：
            - 全部技术路线的比较（例如“为什么不是传统机器学习”）
            - 整个 AI 发展史
            - 所有可能的应用场景
        - 换句话说：你要回答的不是“为什么 LLM 存在”，而是“为什么在‘医学教育 / 临床推理教学’这个领域做这个系统是有意义的、而且目前还没被好好做”。

- motivation 修正：
    - 说明 问题领域 在现实和学术上的重要性
        - 临床推理是医学领域的一个重要任务，对临床推理的显式训练需要耗费大量资源和时间
            - 小组讨论、床边教学、OSCE 等，耗费大量教师时间，且反馈延迟。
            - 所以“如何更系统地教临床推理 + 提供可扩展的个性化反馈”，本身就是一个被反复强调的 open problem。
        - LLM 在医学教育中被认为可以：
            - 支持个性化学习路径、即时反馈、虚拟病人模拟等。
            - 尤其在自然语言交互、生成解释性反馈方面，有传统系统难以比拟的优势。
    - 【todo】指出 目前已有工作 做到了什么
        - 但是，现有 LLM 医学教育工作大多停留在：
            - 评估 LLM 自己在考试/病例上的表现（“LLM 会不会做题/诊断”）。
            - 或者用 LLM 做一次性的评分或反馈（例如给一次 OSCE 答案打分）。
    - 清晰说出 还缺什么（gap）
        - 【nope】目前已有的工作要么关注 LLM 的医疗能力，要么关注 单次任务的评分/反馈。
        - 缺少的，是一个“面向学生”的、围绕临床推理过程设计的**完整**教学系统，具备：
            - 明确的临床任务分解（信息采集、问题表征、DDx 生成与收缩、决策理由等）。
            - LLM 驱动的、多维度（过程+结果）的自动评分机制。
            - 针对学生个人弱点（某步骤、某专科）的纵向评估与可视化追踪。
    - 自己的工作 填补这个 gap 的方式
        - 临床推理领域的任务有哪些
        - LLM 怎么评估？ + 维度限制评估哪些？
        - 学生个人化评估
            - dashboard 总结各个指标（发散能力，知识广度，专科的特定弱点等）
            - 自然语言的个人报告 + 个人化改进建议
        - 【这个可能可用往后放】题目与答案从何而来？
        


    - 【这个可能可用往后放】题目与答案从何而来？
    - 【可以作为下一步，为老师提供自定义的便利性】结构化模块
        - 题目步骤模块，打分模块，评估模块
        - 可以设立要评估哪些步骤，最终的评估能力是什么
    - WHy not other
        - 为什么选“教育 / 学生训练”，而不是直接做“临床决策支持”？
            - 可以用：教育场景风险更低、更适合做原型，而且已有文献强调 LLM 在教育中的巨大潜力。
        - 为什么聚焦“临床推理教学”，而不是“医学知识问答”?
            - 因为临床推理是错误和差异性最大的部分，也是传统教学最难系统化的一块。





# report draft
- Introduction
- motivation
    - 说明 问题领域 在现实和学术上的重要性
        <!-- - 临床推理是医学领域的一个重要任务，对临床推理的显式训练需要耗费大量资源和时间
            - 小组讨论、床边教学、OSCE 等，耗费大量教师时间，且反馈延迟。
            - 所以“如何更系统地教临床推理 + 提供可扩展的个性化反馈”，本身就是一个被反复强调的 open problem。
        - LLM 在医学教育中被认为可以：
            - 支持个性化学习路径、即时反馈、虚拟病人模拟等。
            - 尤其在自然语言交互、生成解释性反馈方面，有传统系统难以比拟的优势。
            - 资料：（https://pmc.ncbi.nlm.nih.gov/articles/PMC11294775/）（https://mededu.jmir.org/2023/1/e48291/）（https://www.nature.com/articles/s43856-023-00370-1） -->
    - 指出 目前已有工作 做到了什么
        
    - 清晰说出 还缺什么（gap）
        - 【nope】目前已有的工作要么关注 LLM 的医疗能力，要么关注 单次任务的评分/反馈。
        - 缺少的，是一个“面向学生”的、围绕临床推理过程设计的**完整**教学系统，具备：
            - 明确的临床任务分解（信息采集、问题表征、DDx 生成与收缩、决策理由等）。
            - LLM 驱动的、多维度（过程+结果）的自动评分机制。
            - 针对学生个人弱点（某步骤、某专科）的纵向评估与可视化追踪。
    - 自己的工作 填补这个 gap 的方式
        1. 基于已有临床推理教学理论、评估⼯具与 LLM 研究，构建⼀个系统整合的"教学步骤 + 评估维度"框架，专注于"教学⽣如何做诊断推理"这⼀件事。
            1. 拆分临床推理步骤 + 设计评估框架
            2. 复⽤现有理论⼯具（CRI‑HT‑S、SNAPPS、IDEA、Revised‑IDEA 等）
        2. 设计⼀套可复⽤的 LLM 评估⼯作流与接⼝
            1. 把零散的 LLM 评分实验沉淀成可落地的教学⼯具模块（评估框架的整合）
            2. 基于 OSCE 多模型合议和 SCT LLM panel 的成功案例，引入简单置信度机制。[102][170]
        3. 为学生提供全面的学习反馈：
            1. 把多维度、纵向的学习数据转化为真实可⽤的个⼈化评估报告和学习建议（利⽤ LLM ⽣成个体化的诊断分析、推理⻛格定性、和可操作的改进建议。）[76][118][178]
        4. 在此基础上，预留虚拟病⼈交互和专科数据拆分作为后续⾃然扩展，使平台能在未来纳入更多能⼒维度（沟通、信息收集策略、专科⼴度等），⽽不改变已有核⼼架构。[40][167][171][127][179]
            1. 还可以进一步涵盖其他医学任务，比如文本撰写，入院预测等等
- how
    1. 临床推理分析
        - 大体框架（https://pmc.ncbi.nlm.nih.gov/articles/PMC5611427/#sec1-2）
            - 线索获取
            - 线索解释/问题表示（https://pmc.ncbi.nlm.nih.gov/articles/PMC5834975/）
            - 假设生成（DDx
            - 假设评估
    2. LLM 工作流
        1. LLM-as-judge
        2. 置信度
        3. 不同的工作流
    3. 学生全面评估
        1. 理论工具
        2. 雷达图
        3. 个人化报告细节
        4. 学习建议