# Stage 1
### Overall map step
1. 跑通基础模型
    1. 闭源
    2. 开源
        1. 通用
        2. 医学领域特有
2. 建立优化工作流
    1. prompt engineering
    2. CoT
    3. multi-agent
        - ReAct
        - 协作式
        - 辩论式
            - Self-Refine + Self-Critique
            - 多样化采样 + 共识（self-consistency）
    4. 工具调用
    5. 安全与对齐层（后处理
3. 在具体医学问题上测试
    - 典型的临床大类包括（不同国家会略有不同）：过于细的亚专科不必全记，只要有整体 map 即可。​
        - 内科：心血管、呼吸、消化、肾脏、内分泌、血液、感染、风湿免疫等。
        - 外科：普通外科、骨科、神经外科、心胸外科、泌尿外科、整形外科等。
        - 妇产科、儿科。
        - 神经科（neurology）、精神科（psychiatry）。
        - 影像科（放射科、超声、核医学）、检验 / 病理等“辅助科室”。
        - 其他：皮肤科、眼科、耳鼻喉、康复医学、急诊医学等
    - 只选择 2–3 个专科场景（比如内科 + 神经科 + 急诊）作为主要实验领域
    - 推理的基本流程
        - 病史采集（history taking）：主诉、现病史、既往史、用药史、家族史、社会史、系统回顾（Review of Systems）。这是“主观信息”。​
        - 体格检查（physical examination）：视诊、触诊、叩诊、听诊，按系统检查（心肺腹、神经系统、肌骨系统等），这是“客观体征”。​
        - 初步诊断与鉴别诊断：基于病史和体检，列出可能疾病的列表（differential diagnosis），并按可能性排序。​
        - 辅助检查：根据推理选择化验（血常规、生化、凝血、心肌标志物）、影像（X 光、CT、MRI、超声）、心电图、内镜等，目的是“确认 / 排除”某些诊断。​
        - 最终诊断和处置计划：结合所有信息，做出诊断（或列出有限备选），并提出治疗和随访计划。

### important problem
- 有观点认为，multi-agent 其实限制很大，主要问题在于‘隐型决策’对其他 agent 不可见。但是辩论式架构仍然有用
- 我们连医学的测试集和测试标准都没有，怎么就敢开始干的

### possible problem pop up (but lower priority)
- 上下文问题 Context Engineering
- privacy 也可以考虑
- 多种不同方案组合，用于选择成本、时间、效果。甚至可以随着用户的对话次数多级递进
- 提供低代码配置平台








# Stage 2
### source
- 临床决策结构的论文：https://arxiv.org/html/2510.20001v1#S4
    - 只是在总结，并没有数据提供
    - 列出了一些值得深究的现有问题
- CoT，few-shot 的方法结果：https://pmc.ncbi.nlm.nih.gov/articles/PMC10935498/
    - 没有多agent，没有开放式题目（只有答案选项	A/B/C/D	是/否/也许）


### 方向：
- 主要方向：不使用RAG和微调的前提下，怎么提升 medical LLM 的输出质量？
- 思路一：对“临床推理质量”的细粒度评估
    - 感觉不太适合，我就是一破搞LLM的，这种细粒度评估和我的主要方向不太契合

- 思路二：思路二：围绕“鲁棒性 / 干扰信息”的医学推理实验，
    - 感觉不太适合，但 ‘prompt & agent 如何提升鲁棒性’ 这个方向是挺好的，可以作为 side-work

- 思路三：把“临床工作流”强制编码进 prompt / agent 框架
    - 创新点：用非常轻量的 prompt / agent 机制，评估「强制工作流化」本身对 reasoning 质量和可审计性的影响，而不是再造一个新模型。
    - 这个挺合适

- 思路四：把“医疗 prompt engineering”做成一个小而规范的研究
    - 把现有 prompt 技术放到同一个医学场景、同一个模型里做「公平对比 + 规范报告」
    - 其实可以融进思路三中一块进行

- 思路五：关注“自信度 / 不确定性表达”的安全性问题
    - 把「prompt / agent 设计」和「校准 / 不确定性」这一维度捆在一起研究，而不是只看 accuracy。
    - 不太合适，但可以作为 side-work

### 架构优化方法
- Common
    - Prompt engineering
        - Generated‑knowledge / evidence‑seeking prompting（其实也就是提供框架）
        - CoT
    - ReAct（推理 -> 行动 -> 推理 -> ...）
- single-agent
    - Self‑critique + self‑refine（后处理）
- multi-agent
    - Self‑consistency
- other
    - 工具调用

### Prompt Engineering（全都有论文支持）
- 基础框架：
    1. **指令**。这是提示的核心指令。它告诉模型你希望它做什么。例如，“概括以下文本”就为模型提供了一个清晰的操作。
        - 避免使用诱导性问题
    2. **信息约束**
        - 角色扮演
        - 场景
        - few-shot 提供样本上下文
        - 安全约束
    3. **格式约束**
        - 强制结构化输出
            - eg 指定分段或项目，如「1. 关键信息摘要；2. 问题列表；3. 鉴别诊断；4. 建议检查；5. 工作诊断与理由」。
- 医学推理的典型工作流（你可以直接转成 prompt 模板）
    - 基础模板
        - 信息收集
            - 病史：主诉、现病史、既往史、用药史、过敏史、家族史、社会史、系统回顾（ROS）。​
            - 体格检查：按系统（心肺腹、神经、肌骨等）记录阳性和阴性体征。​
        - 形成初步问题列表
            - 提取关键问题和症状（problem list），例如「急性胸痛」「发热伴皮疹」等，既考虑症状也考虑体征与检验异常。​
        - 鉴别诊断（differential diagnosis）
            - 基于问题列表和临床知识，列出可能诊断，按「危重优先」和可能性排序。
            - 对每个候选诊断，列支持点和反对点（哪些病史 / 体检 / 实验室结果与之吻合或冲突）。​
        - 选择进一步检查
            - 只做能明显增加信息量的检查（labs、成像、专科检查等），避免“为了检查而检查”。​
            - 每一个检查都应回答一个明确的临床问题（比如“是否有心肌损伤”“是否有肺栓塞”）。​
        - 综合诊断 + 处置计划
            - 根据所有信息更新鉴别诊断，提出工作诊断（working diagnosis）。​
            - 给出初步治疗计划、监测计划和随访安排，同时考虑患者偏好与风险收益。
    - 约束
        - 禁止给药物剂量 / 具体处方；
        - 所有建议为教育用途，不可替代专业医疗；
        - 对任何红旗症状必须明确提醒线下急诊或专科就诊。
    - 总结：
        - problem list
        - top‑3 鉴别诊断（按危重程度排序）
        - 每个诊断的支持 / 反对证据
        - 还需要的检查
        - 暂定工作诊断
        - 约束
- CoT 模板
    - 基础设计 + 显式要求模型「逐步推理」
    - 医学模板：
        - 先概括关键临床要点
        - 再列出所有可能诊断
        - 再一步步排除或支持
- 自审 / 自修模板（self‑refine）
    - 基础设计 + 让模型以“上级医生 / 评审员”身份批评自己的答案，指出潜在错误和遗漏 + 重新生成
- ref
    - 系统性 survey 把各种 prompting 技术总结成“优化问题”：https://traindy.io/wp-content/uploads/2024/12/2024-The-Prompt-Report-A-Systematic-Survey-of-Prompting-Techniques.pdf
    - 整理了 100+ 篇 medical prompt engineering 论文，并给出报告规范与常用范式统计（PD/PL/PT）：https://www.jmir.org/2024/1/e60501/
    - 「先总结疾病特征再诊断」的提示被证明能提高 reasoning 的稳定性：https://www.nature.com/articles/s41586-023-06291-2
    - self-refine：https://arxiv.org/abs/2405.01249
- trial on final version
    - 【1+2】角色与边界（system）
        - 你是一名内科住院医，任务是对病例进行诊断性推理。
        - 输出仅用于教学，不构成实际医疗建议，如有紧急情况应立即就医。​
        - bruh
            ```
            你是一名内科住院医，正在进行病例诊断推理。
            你的回答仅用于教学和研究目的，不构成任何形式的医疗建议或处方。
            如遇任何紧急或危险情况，请明确提示患者立刻线下就医或拨打急救电话。
            ```
    - 【2+3】工作流指令（system 或 user 前缀说明）
        - 步骤 1：用 2–3 句话总结关键病史和体征。
        - 步骤 2：列出与问题相关的疾病 / 机制 / guideline 关键点
        - 步骤 3：列出 3–5 个可能诊断（鉴别诊断），按危重程度排序。
        - 步骤 4：对每个诊断，分别列出支持该诊断的证据和不支持的证据。
        - 步骤 5：提出你认为最需要追加的 2–3 项检查，并说明每项检查想回答什么问题。
        - 步骤 6：给出一个工作诊断，并说明为什么最可能。（要求引用前面步骤的证据）
        - bruh
            ```
            给定以下病例信息，请严格按照步骤进行推理并给出初步诊断意见。
            【病例信息】
            {{CASE_TEXT}}
            请按以下结构输出你的回答：
                关键信息摘要：用 2–4 句话总结患者的主要症状、体征和关键检查结果。
                问题列表（Problem list）：列出 3–6 条你认为最重要的临床问题，包含相关的疾病 / 机制 / guideline 关键点
                鉴别诊断列表：列出 3–5 个可能诊断，按危重程度从高到低排序。
                证据分析：对每个可能诊断，分别列出“支持该诊断的依据”和“不支持或反对该诊断的依据”。
                建议的进一步检查：列出 2–5 项你认为应当进行的进一步检查，并说明每一项检查希望回答的关键临床问题。
                初步工作诊断：给出你认为最可能的诊断，并用 3–5 句话解释理由。
            请完整展示你的推理过程，不要只给出简短结论。
            「请严格按照步骤 1–6 输出，不要跳过推理过程。」
            ```
    - CoT 附加要求
        - 「请严格按照步骤 1–6 输出，不要跳过推理过程。」
    - self-critique
        - bruh
            ```
            你现在的角色是一名有经验的上级医生，你的任务是严格审查一名住院医生写的病例诊断思路与结论。
            请特别关注：是否遗漏危重诊断、是否有与病史/体征矛盾的推理、是否出现过度自信或危险建议。
            你的输出仅用于教学和研究，并不构成任何医疗建议。
            ```
        - bruh2
            ```
            下面是住院医生对某个病例给出的初步分析和诊断，请你进行严格的批评性审查。
            【病例信息】
            {{CASE_TEXT}}
            【住院医生的初稿回答】
            {{DRAFT_ANSWER}}
            请按以下结构输出你的审查意见：
            主要优点：指出该分析中做得较好的 2–4 点。
            主要问题：
                信息遗漏：是否有重要病史、体征或检查结果未被充分考虑？
                推理缺陷：是否存在逻辑跳跃、与病例事实不符的结论？
                危险疏漏：是否遗漏了需要优先排查的危重或高风险诊断？
                不确定性表达：是否在证据不足时给出了过度肯定的结论？
                建议修改方向：用条目形式具体说明应该如何修改 problem list、鉴别诊断、检查计划和工作诊断。
                风险提示建议：指出在向患者沟通时应该加入的安全提示或就医建议。
            ```
    - Self‑refine 
        - bruh
            ```
            你是一名住院医生，已经收到上级医生对你病例分析的详细批评意见。
            现在请你根据这些批评，对自己的分析和诊断进行全面修改和完善。
            你的目标是在保证安全与谨慎的前提下，给出更完整、更严谨的诊断性推理。
            ```
        - bruh2
            ```
            【病例信息】
            {{CASE_TEXT}}
            【你之前的初稿回答】
            {{DRAFT_ANSWER}}
            【上级医生的批评意见】
            {{CRITIQUE}}
            请在综合以上内容的基础上，重新写一份改进后的最终回答。
            要求：
            仍然使用以下结构输出：
                关键信息摘要
                问题列表
                鉴别诊断列表（标出危重优先）
                证据分析（支持/反对）
                建议的进一步检查及理由
                初步工作诊断与解释
            在适当位置明确标注不确定性，并在结尾加入对患者的风险提示和就医建议。
            尽量保留你初稿中正确和有价值的部分，同时修正上级指出的问题，不要简单复制初稿。
            ```

### 评估维度
- 对于开放回答，MultiMedQA 提出了一个多维度人工评估框架：
    - factuality（事实正确性）
    - comprehension（对问题理解）
    - reasoning（推理步骤合理性）
    - possible harm（潜在伤害性）
    - bias（偏见）​
    - 若项目时间有限，可以重点评 factuality + reasoning + harm 三个维度。
- 评估方法：
    - 人工
    - LLM + 人工校准
    - 
- ref
    - Evaluation Framework of Large Language Models in Medical Documentation: Development and Usability Study
        - https://www.jmir.org/2024/1/e58329/
        - 适宜性、准确性、结构/格式、简洁性和临床有效性
    - MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications
        - https://arxiv.org/abs/2409.07314
        - 医学推理、伦理与偏见、数据与语言理解、情境学习以及临床安全
    - A framework for human evaluation of large language models in healthcare derived from literature review
        - https://pubmed.ncbi.nlm.nih.gov/39333376/
        - 信息质量、理解和推理、表达风格和角色、安全性和危害性，以及信任和信心
    - 这些方法大多有专业人士帮忙评估。我们没有，只能尝试通过使用高级模型或者用大量 token 的合作来设立基线

### 数据集
1. MedQA / Med_QA（医学考试题，MCQ）
    - Hugging Face 上有整理好的 MedQA 数据集版本，例如 bigbio/med_qa 和 openlifescienceai/medqa，可以用 datasets.load_dataset 直接加载，也可以网页上点开 Files 手动下载。每条样本包括题干、多个选项、正确答案等。​
    - 类型：单选医学考试题，类似 USMLE 题目，适合做 MCQ 评测。你可以简单采样几百条作为实验子集。​
2. PubMedQA（短文 + yes/no/maybe + rationale）
    - Hugging Face 上的 bigbio/pubmed_qa 提供了 PubMedQA 的结构化版本，包含问题、文章标题、摘要、答案（yes/no/maybe）以及部分有解释。​
    - 官方 GitHub 也提供原始数据和划分脚本（PQA‑L 等），可以手动下载再用 Python 读 JSON。​
    - 类型：
        - 形式上是 yes/no/maybe（相当于三分类/判断题），属于你说的 TF/MCQ 一类；
        - 你可以要求模型给出自然语言解释，把它**当成「有标准标签的开放回答」**来评估 reasoning 质量。
3. 医疗对话 / 开放问答数据（可选）
    - 如果想要更开放一点的长答案 QA，可以考虑：
    - Hugging Face 的 Medical Dialog / MedDialog 数据集，是真实医患对话，可截取问题和医生回答构造开放问答，但版权和隐私要小心。​
    - 一些新近提出的长文 medical QA benchmark（比如 long‑form medical QA），往往提供问题、参考答案和人类评估方案，可以从对应论文 / GitHub 找链接。​
    - 简单配置建议：
        - MCQ/TF 部分：用 MedQA + PubMedQA（yes/no/maybe）就够。
    - 开放回答部分：
        - 让模型对 MedQA/ PubMedQA 的同一题目输出解释（自制 rationale），
        - 或额外抽取少量病例问答/长答案数据用于小规模人工/LLM‑as‑judge 评分。

### trial plan
- 把整条路线打通了先
    - 【算是done了】整个应用的方案
    - 【算是ok了】测试用的数据集
        - 一个 MCQ
        - 一个 开放回答
    - 【single + self-critique&refine】prompt 模板
    - 【资料搜好了】输出结果的评估准则
- 当前要做的事
    - 设计好应用先，确保能够进行实验
    - 提供 single-shot 和 self-refine 这种单模型的 prompt 的完整设计
    - paper work 讲述之后的步骤：
        - 把挑选数据集和评估输出准则这两者往后放，可以先提供 paper work，然后直接用 Poe 的单个 chat 来测试
        - 制作多 agent 架构（包括不同身份各司其职）


### 未来 todo
- reviewer 的 template
- 支持自定义 prompt 输入
- error 处理
- function call 去搜索证据




### 当前成果的汇总，方便讨论
- 什么是诊断，有几个步骤？
- 我对这些步骤做了什么‘数据化’？
- 找到了什么资料和资源？又有什么不足之处是我可以做的？
- 我找了哪些工作流优化方法？有没有效果？